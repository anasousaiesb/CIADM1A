import streamlit as st
import pandas as pd
from datetime import datetime
import io # Necess√°rio para simular nome de arquivo para pd.read_csv de um objeto BytesIO

# Constantes
NOME_CIDADE_DISPLAY = "Brazl√¢ndia (DF)"
CODIGO_ESTACAO = "A042" # C√≥digo da esta√ß√£o para Brazl√¢ndia
ANOS_PARA_ANALISAR = [2020, 2021, 2022, 2023, 2024] # √öltimos 5 anos completos de refer√™ncia
GITHUB_USER = "anasousaiesb"
GITHUB_REPO = "CIADM1A"
GITHUB_BRANCH = "main" # ou 'master', dependendo do reposit√≥rio
BASE_PATH_IN_REPO = "CIADM1A" # Pasta raiz dos dados dentro do reposit√≥rio

COLUNA_PRECIPITACAO_NOME_ORIGINAL = 'PRECIPITA√á√ÉO TOTAL, HOR√ÅRIO (mm)'
COLUNA_DATA_NOME_ORIGINAL = 'Data'
# Assumindo que a coluna 'HORA UTC' tamb√©m existe e √© necess√°ria para a data completa.
COLUNA_HORA_NOME_ORIGINAL = 'Hora UTC' # INMET usa 'HORA UTC' ou similar para a hora. Verifique o nome exato.

def construir_url_arquivo(ano):
    """Constr√≥i a URL para o arquivo de um ano espec√≠fico."""
    nome_arquivo = f"INMET_CO_DF_{CODIGO_ESTACAO}_BRAZLANDIA_01-01-{ano}_A_31-12-{ano}.CSV"
    url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{GITHUB_REPO}/{GITHUB_BRANCH}/{BASE_PATH_IN_REPO}/{ano}/{nome_arquivo}"
    return url

def processar_dados_inmet(df_bruto, nome_arquivo_log):
    """Processa o DataFrame bruto do INMET para o formato necess√°rio."""
    mensagens_processamento = []
    df_selecionado = None

    # Verificar colunas essenciais
    colunas_necessarias = [COLUNA_DATA_NOME_ORIGINAL, COLUNA_HORA_NOME_ORIGINAL, COLUNA_PRECIPITACAO_NOME_ORIGINAL]
    colunas_faltantes = [col for col in colunas_necessarias if col not in df_bruto.columns]

    if colunas_faltantes:
        mensagens_processamento.append(f"AVISO ({nome_arquivo_log}): Colunas faltando: {', '.join(colunas_faltantes)}. Pulando este arquivo.")
        return None, mensagens_processamento

    try:
        # Selecionar colunas e copiar para evitar SettingWithCopyWarning
        df_processado = df_bruto[colunas_necessarias].copy()

        # Converter precipita√ß√£o para num√©rico
        df_processado.loc[:, COLUNA_PRECIPITACAO_NOME_ORIGINAL] = pd.to_numeric(
            df_processado[COLUNA_PRECIPITACAO_NOME_ORIGINAL], errors='coerce'
        )

        # Criar coluna de data/hora completa
        # O formato da hora no INMET √© 'HHMM UTC', precisamos formatar para 'HH:MM:SS'
        # ou apenas 'HH' se for usar s√≥ a hora inteira.
        # Ex: '1300 UTC' -> '13'
        df_processado.loc[:, 'hora_formatada'] = df_processado[COLUNA_HORA_NOME_ORIGINAL].astype(str).str.slice(0, 2).str.zfill(2) + ":00:00"
        
        # Tentar formatos de data comuns do INMET
        try:
            # Tentativa 1: AAAA/MM/DD
            df_processado.loc[:, 'datetime_completo'] = pd.to_datetime(
                df_processado[COLUNA_DATA_NOME_ORIGINAL] + ' ' + df_processado['hora_formatada'],
                format='%Y/%m/%d %H:%M:%S', errors='coerce'
            )
            if df_processado['datetime_completo'].isnull().all(): # Se falhou, tentar outro formato
                raise ValueError("Primeira tentativa de formato de data falhou.")
        except ValueError:
            try:
                # Tentativa 2: DD/MM/AAAA
                df_processado.loc[:, 'datetime_completo'] = pd.to_datetime(
                    df_processado[COLUNA_DATA_NOME_ORIGINAL] + ' ' + df_processado['hora_formatada'],
                    format='%d/%m/%Y %H:%M:%S', errors='coerce'
                )
                if df_processado['datetime_completo'].isnull().all():
                     raise ValueError("Segunda tentativa de formato de data falhou.")
            except Exception as e_dt:
                mensagens_processamento.append(f"AVISO ({nome_arquivo_log}): Falha ao converter data/hora: {e_dt}.")
                return None, mensagens_processamento
        
        # Selecionar e renomear colunas finais
        df_selecionado = df_processado[['datetime_completo', COLUNA_PRECIPITACAO_NOME_ORIGINAL]].copy()
        df_selecionado.rename(columns={
            'datetime_completo': 'data',
            COLUNA_PRECIPITACAO_NOME_ORIGINAL: 'precipitacao_mm'
        }, inplace=True)

        # Remover linhas onde data ou precipita√ß√£o n√£o puderam ser convertidas
        df_selecionado.dropna(subset=['data', 'precipitacao_mm'], inplace=True)
        
    except Exception as e:
        mensagens_processamento.append(f"ERRO ({nome_arquivo_log}): Erro no processamento detalhado: {e}")
        return None, mensagens_processamento
    
    return df_selecionado, mensagens_processamento


def analisar_frequencia_chuva_multi_anos_streamlit(anos_lista, nome_cidade, limiar_chuva_mm):
    resultados = {
        "mensagens_status": [],
        "contagem_eventos_df": None,
        "mensagem_tendencia": "",
        "periodo_analisado_str": "",
        "anos_com_dados": []
    }
    
    todos_os_dados_anuais = []
    
    for ano in anos_lista:
        url = construir_url_arquivo(ano)
        resultados["mensagens_status"].append(f"Tentando carregar dados para {ano} de: {url}")
        
        try:
            # skiprows pode variar; arquivos INMET geralmente t√™m 8 linhas de cabe√ßalho.
            df_bruto_anual = pd.read_csv(
                url,
                decimal=',',
                encoding='latin1', 
                na_values=['null', 'NULL', '', 'NA', '#N/A', 'NA ', '-9999'], # -9999 √© comum em INMET para nulo
                skiprows=8
            )
            
            df_processado_anual, mensagens_proc = processar_dados_inmet(df_bruto_anual, f"Ano {ano}")
            resultados["mensagens_status"].extend(mensagens_proc)

            if df_processado_anual is not None and not df_processado_anual.empty:
                todos_os_dados_anuais.append(df_processado_anual)
                resultados["anos_com_dados"].append(ano)
                resultados["mensagens_status"].append(f"Dados para o ano {ano} carregados e processados com sucesso ({len(df_processado_anual)} registros).")
            else:
                resultados["mensagens_status"].append(f"Nenhum dado v√°lido processado para o ano {ano}.")

        except Exception as e: # Captura HTTPError (para URL n√£o encontrada) e outros erros de leitura
            resultados["mensagens_status"].append(f"AVISO: N√£o foi poss√≠vel carregar ou processar o arquivo para o ano {ano}. URL: {url}. Erro: {e}")

    if not todos_os_dados_anuais:
        resultados["mensagens_status"].append(f"Nenhum dado v√°lido foi carregado para {nome_cidade} para os anos especificados.")
        resultados["mensagem_tendencia"] = "Nenhum dado encontrado para an√°lise."
        return resultados

    df_completo = pd.concat(todos_os_dados_anuais, ignore_index=True)
    resultados["mensagens_status"].append(f"Total de {len(df_completo)} registros hor√°rios carregados dos anos: {', '.join(map(str, sorted(resultados['anos_com_dados'])))}.")

    if df_completo.empty:
        resultados["mensagem_tendencia"] = "Nenhum dado v√°lido ap√≥s concatena√ß√£o."
        return resultados
    
    df_completo.sort_values(by='data', inplace=True) # Ordenar cronologicamente
    
    min_date_str = df_completo['data'].min().strftime('%Y-%m-%d %H:%M')
    max_date_str = df_completo['data'].max().strftime('%Y-%m-%d %H:%M')
    resultados["periodo_analisado_str"] = f"Analisando dados de {min_date_str} at√© {max_date_str}."
    resultados["mensagens_status"].append(resultados["periodo_analisado_str"])
    
    df_completo.loc[:, 'evento_extremo'] = df_completo['precipitacao_mm'] >= limiar_chuva_mm
    df_completo.loc[:, 'ano_evento'] = df_completo['data'].dt.year # Usar 'ano_evento' para evitar conflito com 'ano' da lista de anos
    
    # Contagem de eventos, garantindo todos os anos com dados na sa√≠da, mesmo com 0 eventos.
    anos_unicos_nos_dados = sorted(df_completo['ano_evento'].unique())
    if not anos_unicos_nos_dados: # Seguran√ßa, caso df_completo fique vazio por alguma raz√£o inesperada
        resultados["mensagem_tendencia"] = "Nenhum ano encontrado nos dados ap√≥s processamento."
        return resultados

    contagem_eventos_por_ano = df_completo[df_completo['evento_extremo']].groupby('ano_evento').size().reindex(
        range(min(anos_unicos_nos_dados), max(anos_unicos_nos_dados) + 1), fill_value=0
    )
    
    # Filtrar para apenas os anos que tinham dados
    contagem_eventos_por_ano = contagem_eventos_por_ano[contagem_eventos_por_ano.index.isin(resultados["anos_com_dados"])]

    resultados["contagem_eventos_df"] = contagem_eventos_por_ano.reset_index().rename(
        columns={'ano_evento': 'Ano', 0: 'Eventos Extremos (‚â•50mm)'}
    )


    if contagem_eventos_por_ano.sum() == 0:
        resultados["mensagem_tendencia"] = f"Nenhum evento de chuva extrema (‚â• {limiar_chuva_mm} mm) encontrado para {nome_cidade} nos anos com dados ({', '.join(map(str, resultados['anos_com_dados']))})."
        return resultados
    
    # An√°lise de tend√™ncia
    num_anos_com_eventos_ou_dados = len(contagem_eventos_por_ano)

    if num_anos_com_eventos_ou_dados >= 2:
        anos_ordenados = contagem_eventos_por_ano.index
        # Simples compara√ß√£o da primeira metade com a segunda metade dos anos com dados
        if num_anos_com_eventos_ou_dados >= 3: # Precisa de pelo menos 3 pontos para uma divis√£o minimamente razo√°vel
            meio = num_anos_com_eventos_ou_dados // 2
            media_primeira_metade = contagem_eventos_por_ano.iloc[:meio].mean()
            media_segunda_metade = contagem_eventos_por_ano.iloc[meio:].mean()
            
            if media_segunda_metade > media_primeira_metade:
                resultados["mensagem_tendencia"] = f"Observa-se um aumento na m√©dia de eventos extremos na segunda metade do per√≠odo analisado ({media_segunda_metade:.2f} eventos) em compara√ß√£o com a primeira metade ({media_primeira_metade:.2f} eventos)."
            elif media_segunda_metade < media_primeira_metade:
                resultados["mensagem_tendencia"] = f"Observa-se uma diminui√ß√£o na m√©dia de eventos extremos na segunda metade do per√≠odo analisado ({media_segunda_metade:.2f} eventos) em compara√ß√£o com a primeira metade ({media_primeira_metade:.2f} eventos)."
            else:
                resultados["mensagem_tendencia"] = f"A m√©dia de eventos extremos permaneceu est√°vel entre a primeira e a segunda metade do per√≠odo analisado ({media_primeira_metade:.2f} eventos)."
        elif contagem_eventos_por_ano.iloc[-1] > contagem_eventos_por_ano.iloc[0]:
             resultados["mensagem_tendencia"] = "O n√∫mero de eventos no √∫ltimo ano analisado foi maior que no primeiro."
        elif contagem_eventos_por_ano.iloc[-1] < contagem_eventos_por_ano.iloc[0]:
            resultados["mensagem_tendencia"] = "O n√∫mero de eventos no √∫ltimo ano analisado foi menor que no primeiro."
        else:
            resultados["mensagem_tendencia"] = "O n√∫mero de eventos no √∫ltimo ano analisado foi igual ao do primeiro."

    elif num_anos_com_eventos_ou_dados == 1:
        ano_unico_com_eventos = contagem_eventos_por_ano.index[0]
        num_eventos_ano_unico = contagem_eventos_por_ano.iloc[0]
        resultados["mensagem_tendencia"] = f"Eventos extremos registrados apenas em {ano_unico_com_eventos} ({num_eventos_ano_unico} evento(s)). N√£o √© poss√≠vel analisar tend√™ncia de aumento ou diminui√ß√£o com dados de um √∫nico ano efetivo."
    else:
        resultados["mensagem_tendencia"] = "N√£o h√° dados de eventos suficientes para uma an√°lise de tend√™ncia clara."
        
    return resultados

# --- Interface Streamlit ---
st.set_page_config(layout="wide", page_title=f"An√°lise de Chuvas ({NOME_CIDADE_DISPLAY})")
st.title(f"üåßÔ∏è An√°lise de Frequ√™ncia de Chuvas Extremas: {NOME_CIDADE_DISPLAY}")
st.markdown(f"Analisando eventos de chuva ‚â• 50mm para os anos **{', '.join(map(str, ANOS_PARA_ANALISAR))}**.")
st.markdown(f"Fonte dos dados: Reposit√≥rio GitHub `{GITHUB_USER}/{GITHUB_REPO}` (Esta√ß√£o INMET {CODIGO_ESTACAO}).")

# Inputs na barra lateral
st.sidebar.header("Par√¢metros de An√°lise")
st.sidebar.info(f"Cidade: {NOME_CIDADE_DISPLAY}")
st.sidebar.info(f"Anos alvo: {', '.join(map(str, ANOS_PARA_ANALISAR))}")

limiar_chuva_mm_input = st.sidebar.number_input("Limiar de chuva extrema (mm):", min_value=1.0, value=50.0, step=1.0, format="%.1f")

col_botao, col_resultados = st.columns([1,3])

with col_botao:
    if st.sidebar.button("üîç Analisar Dados", use_container_width=True, type="primary"):
        with st.spinner(f"Analisando dados para {NOME_CIDADE_DISPLAY}... Por favor, aguarde."):
            st.session_state.resultados_analise_brazlandia = analisar_frequencia_multi_anos_streamlit(
                ANOS_PARA_ANALISAR, 
                NOME_CIDADE_DISPLAY,
                limiar_chuva_mm_input
            )
    elif 'resultados_analise_brazlandia' not in st.session_state :
         st.info("‚¨ÖÔ∏è Ajuste o limiar de chuva (se desejar) e clique em 'Analisar Dados' para come√ßar.")


with col_resultados:
    if 'resultados_analise_brazlandia' in st.session_state:
        res = st.session_state.resultados_analise_brazlandia
        
        st.subheader(f"Resultados para: {NOME_CIDADE_DISPLAY}")
        if res["periodo_analisado_str"]:
             st.caption(res["periodo_analisado_str"])
        
        if res["anos_com_dados"]:
            st.write(f"**Anos com dados encontrados e processados:** {', '.join(map(str, sorted(res['anos_com_dados'])))}")
        else:
            st.warning("Nenhum dado encontrado para os anos especificados.")


        if res["contagem_eventos_df"] is not None and not res["contagem_eventos_df"].empty:
            st.markdown(f"#### Frequ√™ncia Anual de Eventos Extremos (‚â•{limiar_chuva_mm_input}mm)")
            
            df_tabela_eventos = res["contagem_eventos_df"]
            st.dataframe(df_tabela_eventos.style.format({"Eventos Extremos (‚â•50mm)": "{:.0f}"}), use_container_width=True)
            
            if not df_tabela_eventos.empty and 'Ano' in df_tabela_eventos.columns:
                df_grafico_eventos = df_tabela_eventos.set_index('Ano')
                st.bar_chart(df_grafico_eventos["Eventos Extremos (‚â•50mm)"])
            
            if res["mensagem_tendencia"]:
                st.markdown("#### Avalia√ß√£o da Tend√™ncia")
                st.info(res["mensagem_tendencia"])
        elif res["mensagem_tendencia"]: 
             st.info(res["mensagem_tendencia"]) # Se n√£o houve eventos, mas h√° uma mensagem sobre isso
        else:
            st.warning("N√£o foram encontrados dados de eventos extremos para exibir ou houve um erro no processamento.")

        with st.expander("Ver Logs de Processamento"):
            for msg in res["mensagens_status"]:
                if "ERRO:" in msg:
                    st.error(msg)
                elif "AVISO:" in msg:
                    st.warning(msg)
                else:
                    st.write(msg) # ou st.text(msg) para preservar formata√ß√£o
    
st.sidebar.markdown("---")
st.sidebar.caption("Aplica√ß√£o para an√°lise de dados meteorol√≥gicos do INMET.")
