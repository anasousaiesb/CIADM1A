import streamlit as st
import pandas as pd
from datetime import datetime
import io # Necessário para simular nome de arquivo para pd.read_csv de um objeto BytesIO

# Constantes
NOME_CIDADE_DISPLAY = "Brazlândia (DF)"
CODIGO_ESTACAO = "A042" # Código da estação para Brazlândia
ANOS_PARA_ANALISAR = [2020, 2021, 2022, 2023, 2024] # Últimos 5 anos completos de referência
GITHUB_USER = "anasousaiesb"
GITHUB_REPO = "CIADM1A"
GITHUB_BRANCH = "main" # ou 'master', dependendo do repositório
BASE_PATH_IN_REPO = "CIADM1A" # Pasta raiz dos dados dentro do repositório

COLUNA_PRECIPITACAO_NOME_ORIGINAL = 'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)'
COLUNA_DATA_NOME_ORIGINAL = 'Data'
# Assumindo que a coluna 'HORA UTC' também existe e é necessária para a data completa.
COLUNA_HORA_NOME_ORIGINAL = 'Hora UTC' # INMET usa 'HORA UTC' ou similar para a hora. Verifique o nome exato.

def construir_url_arquivo(ano):
    """Constrói a URL para o arquivo de um ano específico."""
    nome_arquivo = f"INMET_CO_DF_{CODIGO_ESTACAO}_BRAZLANDIA_01-01-{ano}_A_31-12-{ano}.CSV"
    url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{GITHUB_REPO}/{GITHUB_BRANCH}/{BASE_PATH_IN_REPO}/{ano}/{nome_arquivo}"
    return url

def processar_dados_inmet(df_bruto, nome_arquivo_log):
    """Processa o DataFrame bruto do INMET para o formato necessário."""
    mensagens_processamento = []
    df_selecionado = None

    # Verificar colunas essenciais
    colunas_necessarias = [COLUNA_DATA_NOME_ORIGINAL, COLUNA_HORA_NOME_ORIGINAL, COLUNA_PRECIPITACAO_NOME_ORIGINAL]
    colunas_faltantes = [col for col in colunas_necessarias if col not in df_bruto.columns]

    if colunas_faltantes:
        mensagens_processamento.append(f"AVISO ({nome_arquivo_log}): Colunas faltando: {', '.join(colunas_faltantes)}. Pulando este arquivo.")
        return None, mensagens_processamento

    try:
        # Selecionar colunas e copiar para evitar SettingWithCopyWarning
        df_processado = df_bruto[colunas_necessarias].copy()

        # Converter precipitação para numérico
        df_processado.loc[:, COLUNA_PRECIPITACAO_NOME_ORIGINAL] = pd.to_numeric(
            df_processado[COLUNA_PRECIPITACAO_NOME_ORIGINAL], errors='coerce'
        )

        # Criar coluna de data/hora completa
        # O formato da hora no INMET é 'HHMM UTC', precisamos formatar para 'HH:MM:SS'
        # ou apenas 'HH' se for usar só a hora inteira.
        # Ex: '1300 UTC' -> '13'
        df_processado.loc[:, 'hora_formatada'] = df_processado[COLUNA_HORA_NOME_ORIGINAL].astype(str).str.slice(0, 2).str.zfill(2) + ":00:00"
        
        # Tentar formatos de data comuns do INMET
        try:
            # Tentativa 1: AAAA/MM/DD
            df_processado.loc[:, 'datetime_completo'] = pd.to_datetime(
                df_processado[COLUNA_DATA_NOME_ORIGINAL] + ' ' + df_processado['hora_formatada'],
                format='%Y/%m/%d %H:%M:%S', errors='coerce'
            )
            if df_processado['datetime_completo'].isnull().all(): # Se falhou, tentar outro formato
                raise ValueError("Primeira tentativa de formato de data falhou.")
        except ValueError:
            try:
                # Tentativa 2: DD/MM/AAAA
                df_processado.loc[:, 'datetime_completo'] = pd.to_datetime(
                    df_processado[COLUNA_DATA_NOME_ORIGINAL] + ' ' + df_processado['hora_formatada'],
                    format='%d/%m/%Y %H:%M:%S', errors='coerce'
                )
                if df_processado['datetime_completo'].isnull().all():
                     raise ValueError("Segunda tentativa de formato de data falhou.")
            except Exception as e_dt:
                mensagens_processamento.append(f"AVISO ({nome_arquivo_log}): Falha ao converter data/hora: {e_dt}.")
                return None, mensagens_processamento
        
        # Selecionar e renomear colunas finais
        df_selecionado = df_processado[['datetime_completo', COLUNA_PRECIPITACAO_NOME_ORIGINAL]].copy()
        df_selecionado.rename(columns={
            'datetime_completo': 'data',
            COLUNA_PRECIPITACAO_NOME_ORIGINAL: 'precipitacao_mm'
        }, inplace=True)

        # Remover linhas onde data ou precipitação não puderam ser convertidas
        df_selecionado.dropna(subset=['data', 'precipitacao_mm'], inplace=True)
        
    except Exception as e:
        mensagens_processamento.append(f"ERRO ({nome_arquivo_log}): Erro no processamento detalhado: {e}")
        return None, mensagens_processamento
    
    return df_selecionado, mensagens_processamento


def analisar_frequencia_chuva_multi_anos_streamlit(anos_lista, nome_cidade, limiar_chuva_mm):
    resultados = {
        "mensagens_status": [],
        "contagem_eventos_df": None,
        "mensagem_tendencia": "",
        "periodo_analisado_str": "",
        "anos_com_dados": []
    }
    
    todos_os_dados_anuais = []
    
    for ano in anos_lista:
        url = construir_url_arquivo(ano)
        resultados["mensagens_status"].append(f"Tentando carregar dados para {ano} de: {url}")
        
        try:
            # skiprows pode variar; arquivos INMET geralmente têm 8 linhas de cabeçalho.
            df_bruto_anual = pd.read_csv(
                url,
                decimal=',',
                encoding='latin1', 
                na_values=['null', 'NULL', '', 'NA', '#N/A', 'NA ', '-9999'], # -9999 é comum em INMET para nulo
                skiprows=8
            )
            
            df_processado_anual, mensagens_proc = processar_dados_inmet(df_bruto_anual, f"Ano {ano}")
            resultados["mensagens_status"].extend(mensagens_proc)

            if df_processado_anual is not None and not df_processado_anual.empty:
                todos_os_dados_anuais.append(df_processado_anual)
                resultados["anos_com_dados"].append(ano)
                resultados["mensagens_status"].append(f"Dados para o ano {ano} carregados e processados com sucesso ({len(df_processado_anual)} registros).")
            else:
                resultados["mensagens_status"].append(f"Nenhum dado válido processado para o ano {ano}.")

        except Exception as e: # Captura HTTPError (para URL não encontrada) e outros erros de leitura
            resultados["mensagens_status"].append(f"AVISO: Não foi possível carregar ou processar o arquivo para o ano {ano}. URL: {url}. Erro: {e}")

    if not todos_os_dados_anuais:
        resultados["mensagens_status"].append(f"Nenhum dado válido foi carregado para {nome_cidade} para os anos especificados.")
        resultados["mensagem_tendencia"] = "Nenhum dado encontrado para análise."
        return resultados

    df_completo = pd.concat(todos_os_dados_anuais, ignore_index=True)
    resultados["mensagens_status"].append(f"Total de {len(df_completo)} registros horários carregados dos anos: {', '.join(map(str, sorted(resultados['anos_com_dados'])))}.")

    if df_completo.empty:
        resultados["mensagem_tendencia"] = "Nenhum dado válido após concatenação."
        return resultados
    
    df_completo.sort_values(by='data', inplace=True) # Ordenar cronologicamente
    
    min_date_str = df_completo['data'].min().strftime('%Y-%m-%d %H:%M')
    max_date_str = df_completo['data'].max().strftime('%Y-%m-%d %H:%M')
    resultados["periodo_analisado_str"] = f"Analisando dados de {min_date_str} até {max_date_str}."
    resultados["mensagens_status"].append(resultados["periodo_analisado_str"])
    
    df_completo.loc[:, 'evento_extremo'] = df_completo['precipitacao_mm'] >= limiar_chuva_mm
    df_completo.loc[:, 'ano_evento'] = df_completo['data'].dt.year # Usar 'ano_evento' para evitar conflito com 'ano' da lista de anos
    
    # Contagem de eventos, garantindo todos os anos com dados na saída, mesmo com 0 eventos.
    anos_unicos_nos_dados = sorted(df_completo['ano_evento'].unique())
    if not anos_unicos_nos_dados: # Segurança, caso df_completo fique vazio por alguma razão inesperada
        resultados["mensagem_tendencia"] = "Nenhum ano encontrado nos dados após processamento."
        return resultados

    contagem_eventos_por_ano = df_completo[df_completo['evento_extremo']].groupby('ano_evento').size().reindex(
        range(min(anos_unicos_nos_dados), max(anos_unicos_nos_dados) + 1), fill_value=0
    )
    
    # Filtrar para apenas os anos que tinham dados
    contagem_eventos_por_ano = contagem_eventos_por_ano[contagem_eventos_por_ano.index.isin(resultados["anos_com_dados"])]

    resultados["contagem_eventos_df"] = contagem_eventos_por_ano.reset_index().rename(
        columns={'ano_evento': 'Ano', 0: 'Eventos Extremos (≥50mm)'}
    )


    if contagem_eventos_por_ano.sum() == 0:
        resultados["mensagem_tendencia"] = f"Nenhum evento de chuva extrema (≥ {limiar_chuva_mm} mm) encontrado para {nome_cidade} nos anos com dados ({', '.join(map(str, resultados['anos_com_dados']))})."
        return resultados
    
    # Análise de tendência
    num_anos_com_eventos_ou_dados = len(contagem_eventos_por_ano)

    if num_anos_com_eventos_ou_dados >= 2:
        anos_ordenados = contagem_eventos_por_ano.index
        # Simples comparação da primeira metade com a segunda metade dos anos com dados
        if num_anos_com_eventos_ou_dados >= 3: # Precisa de pelo menos 3 pontos para uma divisão minimamente razoável
            meio = num_anos_com_eventos_ou_dados // 2
            media_primeira_metade = contagem_eventos_por_ano.iloc[:meio].mean()
            media_segunda_metade = contagem_eventos_por_ano.iloc[meio:].mean()
            
            if media_segunda_metade > media_primeira_metade:
                resultados["mensagem_tendencia"] = f"Observa-se um aumento na média de eventos extremos na segunda metade do período analisado ({media_segunda_metade:.2f} eventos) em comparação com a primeira metade ({media_primeira_metade:.2f} eventos)."
            elif media_segunda_metade < media_primeira_metade:
                resultados["mensagem_tendencia"] = f"Observa-se uma diminuição na média de eventos extremos na segunda metade do período analisado ({media_segunda_metade:.2f} eventos) em comparação com a primeira metade ({media_primeira_metade:.2f} eventos)."
            else:
                resultados["mensagem_tendencia"] = f"A média de eventos extremos permaneceu estável entre a primeira e a segunda metade do período analisado ({media_primeira_metade:.2f} eventos)."
        elif contagem_eventos_por_ano.iloc[-1] > contagem_eventos_por_ano.iloc[0]:
             resultados["mensagem_tendencia"] = "O número de eventos no último ano analisado foi maior que no primeiro."
        elif contagem_eventos_por_ano.iloc[-1] < contagem_eventos_por_ano.iloc[0]:
            resultados["mensagem_tendencia"] = "O número de eventos no último ano analisado foi menor que no primeiro."
        else:
            resultados["mensagem_tendencia"] = "O número de eventos no último ano analisado foi igual ao do primeiro."

    elif num_anos_com_eventos_ou_dados == 1:
        ano_unico_com_eventos = contagem_eventos_por_ano.index[0]
        num_eventos_ano_unico = contagem_eventos_por_ano.iloc[0]
        resultados["mensagem_tendencia"] = f"Eventos extremos registrados apenas em {ano_unico_com_eventos} ({num_eventos_ano_unico} evento(s)). Não é possível analisar tendência de aumento ou diminuição com dados de um único ano efetivo."
    else:
        resultados["mensagem_tendencia"] = "Não há dados de eventos suficientes para uma análise de tendência clara."
        
    return resultados

# --- Interface Streamlit ---
st.set_page_config(layout="wide", page_title=f"Análise de Chuvas ({NOME_CIDADE_DISPLAY})")
st.title(f"🌧️ Análise de Frequência de Chuvas Extremas: {NOME_CIDADE_DISPLAY}")
st.markdown(f"Analisando eventos de chuva ≥ 50mm para os anos **{', '.join(map(str, ANOS_PARA_ANALISAR))}**.")
st.markdown(f"Fonte dos dados: Repositório GitHub `{GITHUB_USER}/{GITHUB_REPO}` (Estação INMET {CODIGO_ESTACAO}).")

# Inputs na barra lateral
st.sidebar.header("Parâmetros de Análise")
st.sidebar.info(f"Cidade: {NOME_CIDADE_DISPLAY}")
st.sidebar.info(f"Anos alvo: {', '.join(map(str, ANOS_PARA_ANALISAR))}")

limiar_chuva_mm_input = st.sidebar.number_input("Limiar de chuva extrema (mm):", min_value=1.0, value=50.0, step=1.0, format="%.1f")

col_botao, col_resultados = st.columns([1,3])

with col_botao:
    if st.sidebar.button("🔍 Analisar Dados", use_container_width=True, type="primary"):
        with st.spinner(f"Analisando dados para {NOME_CIDADE_DISPLAY}... Por favor, aguarde."):
            st.session_state.resultados_analise_brazlandia = analisar_frequencia_multi_anos_streamlit(
                ANOS_PARA_ANALISAR, 
                NOME_CIDADE_DISPLAY,
                limiar_chuva_mm_input
            )
    elif 'resultados_analise_brazlandia' not in st.session_state :
         st.info("⬅️ Ajuste o limiar de chuva (se desejar) e clique em 'Analisar Dados' para começar.")


with col_resultados:
    if 'resultados_analise_brazlandia' in st.session_state:
        res = st.session_state.resultados_analise_brazlandia
        
        st.subheader(f"Resultados para: {NOME_CIDADE_DISPLAY}")
        if res["periodo_analisado_str"]:
             st.caption(res["periodo_analisado_str"])
        
        if res["anos_com_dados"]:
            st.write(f"**Anos com dados encontrados e processados:** {', '.join(map(str, sorted(res['anos_com_dados'])))}")
        else:
            st.warning("Nenhum dado encontrado para os anos especificados.")


        if res["contagem_eventos_df"] is not None and not res["contagem_eventos_df"].empty:
            st.markdown(f"#### Frequência Anual de Eventos Extremos (≥{limiar_chuva_mm_input}mm)")
            
            df_tabela_eventos = res["contagem_eventos_df"]
            st.dataframe(df_tabela_eventos.style.format({"Eventos Extremos (≥50mm)": "{:.0f}"}), use_container_width=True)
            
            if not df_tabela_eventos.empty and 'Ano' in df_tabela_eventos.columns:
                df_grafico_eventos = df_tabela_eventos.set_index('Ano')
                st.bar_chart(df_grafico_eventos["Eventos Extremos (≥50mm)"])
            
            if res["mensagem_tendencia"]:
                st.markdown("#### Avaliação da Tendência")
                st.info(res["mensagem_tendencia"])
        elif res["mensagem_tendencia"]: 
             st.info(res["mensagem_tendencia"]) # Se não houve eventos, mas há uma mensagem sobre isso
        else:
            st.warning("Não foram encontrados dados de eventos extremos para exibir ou houve um erro no processamento.")

        with st.expander("Ver Logs de Processamento"):
            for msg in res["mensagens_status"]:
                if "ERRO:" in msg:
                    st.error(msg)
                elif "AVISO:" in msg:
                    st.warning(msg)
                else:
                    st.write(msg) # ou st.text(msg) para preservar formatação
    
st.sidebar.markdown("---")
st.sidebar.caption("Aplicação para análise de dados meteorológicos do INMET.")
